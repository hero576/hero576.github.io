
<!DOCTYPE html>
<html lang="zh-CN">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="hero576的博客">
    <title>聚类算法 - hero576的博客</title>
    <meta name="author" content="hero576">
    
        <meta name="keywords" content="py通红,">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"hero576","sameAs":["https://github.com/","http://stackoverflow.com/users","https://twitter.com/","https://facebook.com/","https://plus.google.com/","https://www.linkedin.com/profile/","mailto"]},"articleBody":"聚类可以说是一种无监督的学习，也就是说在训练样本中对应的标记信息是没有的，目标是通过对无标记训练样本的学习来揭示数据内在性质和规律，为进一步的数据分析提供基础。\n聚类的任务聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”。\n性能度量簇内相似度高，簇间相似度低。 \n\n外部指标：是将聚类结果与某个“参考模型”进行比较 \n内部指标：直接考察聚类结果而不利用任何参考模型。\n\n距离计算距离度量满足的基本性质：非负性、同一性、对称性、直递性 \n\n闵可夫斯基距离：$distmk=(n∑u=1|xiu−xju|p)1p$\n如果p=2时，则表示欧氏距离 \n如果p=1时，则表示曼哈顿距离\n\n\n有序属性： \n无序属性：闵可夫斯基可以用于无序属性。对于无序属性可以采用VDM\n\n原型聚类原型聚类亦称“基于原型的聚类”，常用的原型聚类算法如下 \n\nK均值聚类(Kmeans)\n学习向量量化\n高斯混合聚类(GMM)\n\nK值的确定：知乎的回答\n\n数据的先验知识，或者数据进行简单分析能得到\n基于变化的算法：即定义一个函数，随着K的改变，认为在正确的K时会产生极值。如Gap Statistic（Estimating the number of clusters in a data set via the gap statistic, Tibshirani, Walther, and Hastie 2001），Jump Statistic （finding the number of clusters in a data set, Sugar and James 2003）\n基于结构的算法：即比较类内距离、类间距离以确定K。这个也是最常用的办法，如使用平均轮廓系数，越趋近1聚类效果越好；如计算类内距离/类间距离，值越小越好；等。\n基于一致性矩阵的算法：即认为在正确的K时，不同次聚类的结果会更加相似，以此确定K。基于层次聚类：即基于合并或分裂的思想，在一定情况下停止从而获得K。\n基于采样的算法：即对样本采样，分别做聚类；根据这些结果的相似性确定K。如，将样本分为训练与测试样本；对训练样本训练分类器，用于预测测试样本类别，并与聚类的类别比较。\n\n密度聚类基于密度的聚类算法主要的目标是寻找被低密度区域分离的高密度区域。与基于距离的聚类算法不同的是，基于距离的聚类算法的聚类结果是球状的簇，而基于密度的聚类算法可以发现任意形状的聚类，这对于带有噪音点的数据起着重要的作用。 \n层次聚类层次聚类也叫连通聚类方法，有两个基本方法：自顶而下和自底而上。自顶而将所有样本看做是同一簇，然后进行分裂。自底而上将初所有样本看做不同的簇，然后进行凝聚。这种聚类的中心思想是：离观测点较近的点相比离观测点较远的点更可能是一类。过程如下：\n\n把每个样本归为一类，计算两个类之间的距离；\n寻找各类之间最近的两个类归为一类；\n重新计算新生成的这个类与旧类之间的相似度；\n重复2到3，直到所有样本归为一类停止。\n\n实际上聚类过程就是建立了一棵树：可以在中间过程设置阈值，当两个类距离大于阈值，则迭代终止。\n第三步相似度的度量有很多方法，例如：\n\n两个类之间距离最近的两个样本的距离\n两个类之间距离最远的两个样本的距离\n两个类的样本平均距离\n两个类的样本中位数的距离\n\n神经网络ART网络ART（Adaptive Resonance Theory，自适应谐振理论）竞争学习的代表，是一种常用的无监督学习策略。该策略网络输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活。其他神经元被抑制。包含比较层、识别层、识别阈值和重置模块。\nSOM网络SOM（Self-Organizing Map，自组织映射）网络是最常用的聚类方法之一： \n\n竞争型的无监督神经网络\n将高维数据映射到低维空间，并保持输入数据在高维空间的拓扑结构。即将高维空间中相似的样本点映射到网络输出层中邻近神经元\n每个神经元拥有一个权向量\n目标：为每个输出层神经元找到合适的权向量以保持拓扑结构\n\n训练\n\n网络接收输入样本后，将会确定输出层的“获胜”神经元（“胜者通吃”）\n获胜神经元的权向量将向当前输入样本移动\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import numpy as npdef kmeans(x,k,maxIt):    numPoints,numDim=x.shape    dataSet=np.zeros((numPoints,numDim+1))    dataSet[:,:-1]=x    centroids=dataSet[np.random.randint(numPoints,size=k),:]#     centroids=dataSet[0:2,:]    centroids[:,-1]=range(1,k+1)    iterations=0    oldCentroids=None    while not shouldstop(oldCentroids,centroids,iterations,maxIt):        print(iterations,dataSet,centroids)        oldCentroids=np.copy(centroids)        iterations+=1        updateLabels(dataSet,centroids)        centroids=getCentroids(dataSet,k)    return dataSetdef shouldstop(oldCentroids,centroids,iterations,maxIt):    if iterations&gt;maxIt:        return True    return np.array_equal(oldCentroids,centroids)def updateLabels(dataSet,centroids):    numPoints,numDim=dataSet.shape    for i in range(0,numPoints):        dataSet[i,-1]=getLabelFromClosestCentroid(dataSet[i,:-1],centroids)        def getLabelFromClosestCentroid(dataSetRow,centroids):    label=centroids[0,-1]    minDist=np.linalg.norm(dataSetRow-centroids[0,:-1])    for i in range(1,centroids.shape[0]):        dist=np.linalg.norm(dataSetRow-centroids[i,:-1])        if dist&lt;minDist:            minDist=dist            label=centroids[i,-1]    print(minDist)    return label        def getCentroids(dataSet,k):    result=np.zeros((k,dataSet.shape[1]))        for i in range(1,k+1):        oneCluster=dataSet[dataSet[:,-1]==i,:-1]        result[i-1,:-1]=np.mean(oneCluster,axis=0)        result[i-1,-1]=i    return result        x1=np.array([1,1])x2=np.array([2,1])x3=np.array([4,3])x4=np.array([5,4])testX=np.vstack((x1,x2,x3,x4))result=kmeans(testX,2,10)print(result)\n层次聚类的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import numpy as npfrom numpy import *import osfrom PIL import Image,ImageDrawclass Cluster_node:    def __init__(self,vec,left=None,right=None,distance=0.0,id=None,count=1):        self.vec=vec        self.left=left        self.right=right        self.distance=distance        self.id=id        self.count=countdef L2dist(v1,v2):    return np.linalg.norm(v1-v2,ord=2)def hcluster(features,distance=L2dist):    distances=&#123;&#125;    currentclustid=-1    clust=[Cluster_node(array(features[i]),id=i) for i in range(len(features))]    while len(clust)&gt;1:        lowestpair=(0,1)        closest=distance(clust[0].vec,clust[1].vec)        for i in range(len(clust)):            for j in range(i+1,len(clust)):                if (clust[i].id,clust[j].id) not in distances:                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)                d=distances[(clust[i].id,clust[j].id)]                if d&lt;closest:                    closest=d                    lowestpair=(i,j)        mergevec=[(clust[lowestpair[0]].vec[i]+clust[lowestpair[1]].vec[i])/2 for i in range(len(clust[0].vec))]        newcluster=Cluster_node(array(mergevec),left=clust[lowestpair[0]],right=clust[lowestpair[1]],distance=closest,id=currentclustid)        currentclustid-=1        del clust[lowestpair[1]]        del clust[lowestpair[0]]        clust.append(newcluster)    return clust[0]def extract_clusters(clust,dist):    clusters=&#123;&#125;    if clust.distance&lt;dist:        return [clust]    else:        cl=[]        cr=[]        if clust.left!=None:            c1=extract_clusters(clust.left,dist=dist)        if clust.right!=None:            cr=extract_clusters(clust.right,dist=dist)        return cl+crdef get_cluster_elements(clust):    if clust.id&gt;=0:        return [clust.id]    else:        cl=[]        cr=[]        if clust.left!=None:            c1=get_cluster_elements(clust.left)        if clust.right!=None:            cr=get_cluster_elements(clust.right)        return cl+crdef printclust(clust,labels=None,n=0):    for i in range(n):        print(' ',end='')    if clust.id&lt;0:        print('-',end='')    else:        if labels==None:            print(clust.id,end='')        else:            print(labels[clust.id],end='')    if clust.left!=None:        printclust(clust.left,labels=labels,n=n+1)    if clust.right!=None:        printclust(clust.right,labels=labels,n=n+1)def getheight(clust):    if clust.left==None and clust.right==None:        return 1    return getheight(clust.left)+getheight(clust.right)def getdepth(clust):    if clust.left==None and clust.right==None:        return 0    return max(getheight(clust.left),getheight(clust.right))+clust.distance\n下面是几个城市的GDP等信息，根据这些信息，写一个SOM网络，使之对下面城市进行聚类。并且，将结果画在一个二维平面上。\n//表1中，X。为人均GDP(元)；X2为工业总产值(亿元)；X。为社会消费品零售总额(亿元)；x。为批发零售贸易总额(亿元)；x。为地区货运总量(万吨)，表1中数据来自2002年城市统计年鉴。\n//城市 X1 X2 X3 Xa X5北京 27527 2738.30 1494.83 3055.63 30500青岛 29682 1212.02 182.80 598.06 29068天津 22073 2663.56 782.33 1465.65 28151烟台 21017 298.73 92.71 227.39 8178石家庄 25584 467.42 156.02 763.46 12415郑州 17330 261.80 215.63 402.98 7373唐山 19387 338.67 95.73 199.69 14522武汉 17882 1020.84 685.82 1452 16244太原 13919 304.13 141.94 155.22 15170长沙 26327 241.76 269.93 369.83 7550呼和浩特 13738 82.23 69.27 108.12 2415衡阳 12386 61.53 63.95 72.65 3004沈阳 21736 729.04 590.26 1752.4 15156广州 42828 2446.97 1166.10 3214.19 24500大连 34659 1003.56 431.83 728.08 19736深圳 152099 3079.63 609.26 801.06 5167长春 24799 900.26 309.75 173.99 10346油头 19414 192.93 112.96 280.84 1443哈尔滨 20737 402.73 360.38 762.94 8814湛江 15290 228.45 99.08 149.16 5524上海 40788 6935.57 1531.89 3921.2 49499南宁 17715 109.39 142.08 264.32 3371南京 26697 1579.21 401.20 1253.73 14120柳州 17598 256.76 68.93 159.44 3397徐州 19727 295.73 108.17 187.39 7124海口 24782 100.13 81.03 142.54 2018连云港 17869 112.18 47.94 134.89 4096成都 22956 412.23 400.56 754.07 23724杭州 31784 1615.63 373.28 1788.29 15841重庆 9778 870.82 389.60 823.72 29470宁波 46471 751.58 167.70 529.68 11182贵阳 13176 207.95 108.93 285.27 4885温州 29781 381.93 233.44 272.84 6292昆明 24554 303.78 227.44 428.64 12084合肥 19770 330.14 140.14 328.98 2903西安 16002 449.14 323.37 558.27 7728福州 33570 379.51 209.72 613.24 7280兰州 16629 354.30 163.97 374.9 5401厦门 42039 803.29 186.55 620.47 2547西宁 7261 38.00 48.95 91.14 1837南昌 19923 238.82 14.09 348.21 3246银川 12779 77.74 41.22 53.16 1573济南 25642 616.97 323.08 462.39 13057乌鲁木齐 19793 251.19 129.05 277.8 9283\n12345678910111213141516import pandas as pdresult = pd.read_csv('./data/diqu.csv',sep='\\s+',encoding='gbk')# 将result归一化# 标准化操作：from sklearn.preprocessing import StanderdScaler# result_std=StandardScaler().fit_transform(reslut)result_norm = (result.iloc[:,1:] - result.iloc[:,1:].min()) / (result.iloc[:,1:].max() - result.iloc[:,1:].min())result_norm.head()from sklearn.cluster import KMeanskmeans_model=KMeans(n_clusters=4,random_state=1)senator_distances=kmeans_model.fit_transform(result_norm.iloc[:,1:])labels=kmeans_model.labels_print(pd.crosstab(labels,result['城市']))# democratic_outliers=votes[(labels==1)&amp;(result['party']!='D')]import matplotlib.pyplot as pltplt.scatter(x=senator_distances[:,0],y=senator_distances[:,1],c=labels)plt.show()\n\n","dateCreated":"2018-04-24T19:41:00+08:00","dateModified":"2018-06-13T13:41:03+08:00","datePublished":"2018-04-24T19:41:00+08:00","description":"","headline":"聚类算法","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"http://guoming576.cn/2018/04/24/聚类算法/"},"publisher":{"@type":"Organization","name":"hero576","sameAs":["https://github.com/","http://stackoverflow.com/users","https://twitter.com/","https://facebook.com/","https://plus.google.com/","https://www.linkedin.com/profile/","mailto"]},"url":"http://guoming576.cn/2018/04/24/聚类算法/","keywords":"机器学习"}</script>
    <meta name="description" content="聚类可以说是一种无监督的学习，也就是说在训练样本中对应的标记信息是没有的，目标是通过对无标记训练样本的学习来揭示数据内在性质和规律，为进一步的数据分析提供基础。 聚类的任务聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”。 性能度量簇内相似度高，簇间相似度低。   外部指标：是将聚类结果与某个“参考模型”进行比较  内部指标：直接考察聚类结果而不利用任何参考模型。">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="blog">
<meta property="og:title" content="聚类算法">
<meta property="og:url" content="http://guoming576.cn/2018/04/24/聚类算法/index.html">
<meta property="og:site_name" content="hero576的博客">
<meta property="og:description" content="聚类可以说是一种无监督的学习，也就是说在训练样本中对应的标记信息是没有的，目标是通过对无标记训练样本的学习来揭示数据内在性质和规律，为进一步的数据分析提供基础。 聚类的任务聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”。 性能度量簇内相似度高，簇间相似度低。   外部指标：是将聚类结果与某个“参考模型”进行比较  内部指标：直接考察聚类结果而不利用任何参考模型。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://guoming576.cn/images/pasted-76.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-77.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-78.png">
<meta property="og:updated_time" content="2018-06-13T05:41:03.879Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="聚类算法">
<meta name="twitter:description" content="聚类可以说是一种无监督的学习，也就是说在训练样本中对应的标记信息是没有的，目标是通过对无标记训练样本的学习来揭示数据内在性质和规律，为进一步的数据分析提供基础。 聚类的任务聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”。 性能度量簇内相似度高，簇间相似度低。   外部指标：是将聚类结果与某个“参考模型”进行比较  内部指标：直接考察聚类结果而不利用任何参考模型。">
<meta name="twitter:image" content="http://guoming576.cn/images/pasted-76.png">
    
    
        
    
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/all.css">
    <link rel="stylesheet" href="/assets/css/jquery.fancybox.css">
    <link rel="stylesheet" href="/assets/css/thumbs.css">
    <link rel="stylesheet" href="/assets/css/tranquilpeak.css">
    <!--STYLES END-->
    

    

    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/ "
            aria-label=""
        >
            hero576的博客
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Öffne den Link: /#about"
            >
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Kategorien"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Kategorien</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archiv"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archiv</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="Suche"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Suche</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="Über"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Über</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="http://stackoverflow.com/users"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Stack Overflow"
                        >
                        <i class="sidebar-button-icon fab fa-stack-overflow" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Stack Overflow</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://facebook.com/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Facebook"
                        >
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://plus.google.com/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Google Plus"
                        >
                        <i class="sidebar-button-icon fab fa-google-plus" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Google Plus</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.linkedin.com/profile/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="LinkedIn"
                        >
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/mailto"
                            
                            rel="noopener"
                            title="E-Mail"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">E-Mail</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            聚类算法
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2018-04-24T19:41:00+08:00">
	
		    24 4月 2018
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/机器学习/">机器学习</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>聚类可以说是一种无监督的学习，也就是说在训练样本中对应的标记信息是没有的，目标是通过对无标记训练样本的学习来揭示数据内在性质和规律，为进一步的数据分析提供基础。</p>
<h3 id="聚类的任务"><a href="#聚类的任务" class="headerlink" title="聚类的任务"></a>聚类的任务</h3><p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”。</p>
<h3 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h3><p>簇内相似度高，簇间相似度低。 </p>
<ul>
<li>外部指标：是将聚类结果与某个“参考模型”进行比较 </li>
<li>内部指标：直接考察聚类结果而不利用任何参考模型。</li>
</ul>
<h3 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h3><p>距离度量满足的基本性质：非负性、同一性、对称性、直递性 </p>
<ul>
<li>闵可夫斯基距离：$distmk=(n∑u=1|xiu−xju|p)1p$<ul>
<li>如果p=2时，则表示欧氏距离 </li>
<li>如果p=1时，则表示曼哈顿距离</li>
</ul>
</li>
<li>有序属性： </li>
<li>无序属性：闵可夫斯基可以用于无序属性。对于无序属性可以采用VDM</li>
</ul>
<h2 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h2><p>原型聚类亦称“基于原型的聚类”，常用的原型聚类算法如下 </p>
<ul>
<li>K均值聚类(Kmeans)</li>
<li>学习向量量化</li>
<li><a href="http://www.cnblogs.com/mmziscoming/p/5750849.html" target="_blank" rel="noopener">高斯混合聚类(GMM)</a></li>
</ul>
<p><a href="http://www.cnblogs.com/kemaswill/archive/2013/01/26/2877434.html" target="_blank" rel="noopener">K值的确定</a>：<br><a href="https://www.zhihu.com/question/29208148/answer/141482198" target="_blank" rel="noopener">知乎的回答</a></p>
<ul>
<li>数据的先验知识，或者数据进行简单分析能得到</li>
<li>基于变化的算法：即定义一个函数，随着K的改变，认为在正确的K时会产生极值。如Gap Statistic（Estimating the number of clusters in a data set via the gap statistic, Tibshirani, Walther, and Hastie 2001），Jump Statistic （finding the number of clusters in a data set, Sugar and James 2003）</li>
<li>基于结构的算法：即比较类内距离、类间距离以确定K。这个也是最常用的办法，如使用平均轮廓系数，越趋近1聚类效果越好；如计算类内距离/类间距离，值越小越好；等。</li>
<li>基于一致性矩阵的算法：即认为在正确的K时，不同次聚类的结果会更加相似，以此确定K。基于层次聚类：即基于合并或分裂的思想，在一定情况下停止从而获得K。</li>
<li>基于采样的算法：即对样本采样，分别做聚类；根据这些结果的相似性确定K。如，将样本分为训练与测试样本；对训练样本训练分类器，用于预测测试样本类别，并与聚类的类别比较。</li>
</ul>
<h2 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h2><p>基于密度的聚类算法主要的目标是寻找被低密度区域分离的高密度区域。与基于距离的聚类算法不同的是，基于距离的聚类算法的聚类结果是球状的簇，而基于密度的聚类算法可以发现任意形状的聚类，这对于带有噪音点的数据起着重要的作用。 </p>
<h2 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h2><p>层次聚类也叫连通聚类方法，有两个基本方法：自顶而下和自底而上。自顶而将所有样本看做是同一簇，然后进行分裂。自底而上将初所有样本看做不同的簇，然后进行凝聚。这种聚类的中心思想是：离观测点较近的点相比离观测点较远的点更可能是一类。<br>过程如下：</p>
<ol>
<li>把每个样本归为一类，计算两个类之间的距离；</li>
<li>寻找各类之间最近的两个类归为一类；</li>
<li>重新计算新生成的这个类与旧类之间的相似度；</li>
<li>重复2到3，直到所有样本归为一类停止。</li>
</ol>
<p>实际上聚类过程就是建立了一棵树：<br><img src="/images/pasted-76.png" alt="upload successful"><br>可以在中间过程设置阈值，当两个类距离大于阈值，则迭代终止。</p>
<p>第三步相似度的度量有很多方法，例如：</p>
<ul>
<li>两个类之间距离最近的两个样本的距离</li>
<li>两个类之间距离最远的两个样本的距离</li>
<li>两个类的样本平均距离</li>
<li>两个类的样本中位数的距离</li>
</ul>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="ART网络"><a href="#ART网络" class="headerlink" title="ART网络"></a>ART网络</h3><p>ART（Adaptive Resonance Theory，自适应谐振理论）竞争学习的代表，是一种常用的无监督学习策略。该策略网络输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活。其他神经元被抑制。包含比较层、识别层、识别阈值和重置模块。</p>
<h3 id="SOM网络"><a href="#SOM网络" class="headerlink" title="SOM网络"></a>SOM网络</h3><p><img src="/images/pasted-77.png" alt="upload successful"><br>SOM（Self-Organizing Map，自组织映射）网络是最常用的聚类方法之一： </p>
<ul>
<li>竞争型的无监督神经网络</li>
<li>将高维数据映射到低维空间，并保持输入数据在高维空间的拓扑结构。即将高维空间中相似的样本点映射到网络输出层中邻近神经元</li>
<li>每个神经元拥有一个权向量</li>
<li>目标：为每个输出层神经元找到合适的权向量以保持拓扑结构</li>
</ul>
<p>训练</p>
<ul>
<li>网络接收输入样本后，将会确定输出层的“获胜”神经元（“胜者通吃”）</li>
<li>获胜神经元的权向量将向当前输入样本移动</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kmeans</span><span class="params">(x,k,maxIt)</span>:</span></span><br><span class="line">    numPoints,numDim=x.shape</span><br><span class="line">    dataSet=np.zeros((numPoints,numDim+<span class="number">1</span>))</span><br><span class="line">    dataSet[:,:<span class="number">-1</span>]=x</span><br><span class="line">    centroids=dataSet[np.random.randint(numPoints,size=k),:]</span><br><span class="line"><span class="comment">#     centroids=dataSet[0:2,:]</span></span><br><span class="line">    centroids[:,<span class="number">-1</span>]=range(<span class="number">1</span>,k+<span class="number">1</span>)</span><br><span class="line">    iterations=<span class="number">0</span></span><br><span class="line">    oldCentroids=<span class="keyword">None</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> shouldstop(oldCentroids,centroids,iterations,maxIt):</span><br><span class="line">        print(iterations,dataSet,centroids)</span><br><span class="line">        oldCentroids=np.copy(centroids)</span><br><span class="line">        iterations+=<span class="number">1</span></span><br><span class="line">        updateLabels(dataSet,centroids)</span><br><span class="line">        centroids=getCentroids(dataSet,k)</span><br><span class="line">    <span class="keyword">return</span> dataSet</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shouldstop</span><span class="params">(oldCentroids,centroids,iterations,maxIt)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> iterations&gt;maxIt:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">return</span> np.array_equal(oldCentroids,centroids)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateLabels</span><span class="params">(dataSet,centroids)</span>:</span></span><br><span class="line">    numPoints,numDim=dataSet.shape</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,numPoints):</span><br><span class="line">        dataSet[i,<span class="number">-1</span>]=getLabelFromClosestCentroid(dataSet[i,:<span class="number">-1</span>],centroids)        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLabelFromClosestCentroid</span><span class="params">(dataSetRow,centroids)</span>:</span></span><br><span class="line">    label=centroids[<span class="number">0</span>,<span class="number">-1</span>]</span><br><span class="line">    minDist=np.linalg.norm(dataSetRow-centroids[<span class="number">0</span>,:<span class="number">-1</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,centroids.shape[<span class="number">0</span>]):</span><br><span class="line">        dist=np.linalg.norm(dataSetRow-centroids[i,:<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">if</span> dist&lt;minDist:</span><br><span class="line">            minDist=dist</span><br><span class="line">            label=centroids[i,<span class="number">-1</span>]</span><br><span class="line">    print(minDist)</span><br><span class="line">    <span class="keyword">return</span> label        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCentroids</span><span class="params">(dataSet,k)</span>:</span></span><br><span class="line">    result=np.zeros((k,dataSet.shape[<span class="number">1</span>]))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,k+<span class="number">1</span>):</span><br><span class="line">        oneCluster=dataSet[dataSet[:,<span class="number">-1</span>]==i,:<span class="number">-1</span>]</span><br><span class="line">        result[i<span class="number">-1</span>,:<span class="number">-1</span>]=np.mean(oneCluster,axis=<span class="number">0</span>)</span><br><span class="line">        result[i<span class="number">-1</span>,<span class="number">-1</span>]=i</span><br><span class="line">    <span class="keyword">return</span> result        </span><br><span class="line">x1=np.array([<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">x2=np.array([<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">x3=np.array([<span class="number">4</span>,<span class="number">3</span>])</span><br><span class="line">x4=np.array([<span class="number">5</span>,<span class="number">4</span>])</span><br><span class="line">testX=np.vstack((x1,x2,x3,x4))</span><br><span class="line"></span><br><span class="line">result=kmeans(testX,<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<p>层次聚类的实现<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image,ImageDraw</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cluster_node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,vec,left=None,right=None,distance=<span class="number">0.0</span>,id=None,count=<span class="number">1</span>)</span>:</span></span><br><span class="line">        self.vec=vec</span><br><span class="line">        self.left=left</span><br><span class="line">        self.right=right</span><br><span class="line">        self.distance=distance</span><br><span class="line">        self.id=id</span><br><span class="line">        self.count=count</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L2dist</span><span class="params">(v1,v2)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.linalg.norm(v1-v2,ord=<span class="number">2</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hcluster</span><span class="params">(features,distance=L2dist)</span>:</span></span><br><span class="line">    distances=&#123;&#125;</span><br><span class="line">    currentclustid=<span class="number">-1</span></span><br><span class="line">    clust=[Cluster_node(array(features[i]),id=i) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(features))]</span><br><span class="line">    <span class="keyword">while</span> len(clust)&gt;<span class="number">1</span>:</span><br><span class="line">        lowestpair=(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">        closest=distance(clust[<span class="number">0</span>].vec,clust[<span class="number">1</span>].vec)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(clust)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,len(clust)):</span><br><span class="line">                <span class="keyword">if</span> (clust[i].id,clust[j].id) <span class="keyword">not</span> <span class="keyword">in</span> distances:</span><br><span class="line">                    distances[(clust[i].id,clust[j].id)]=distance(clust[i].vec,clust[j].vec)</span><br><span class="line">                d=distances[(clust[i].id,clust[j].id)]</span><br><span class="line">                <span class="keyword">if</span> d&lt;closest:</span><br><span class="line">                    closest=d</span><br><span class="line">                    lowestpair=(i,j)</span><br><span class="line">        mergevec=[(clust[lowestpair[<span class="number">0</span>]].vec[i]+clust[lowestpair[<span class="number">1</span>]].vec[i])/<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(clust[<span class="number">0</span>].vec))]</span><br><span class="line">        newcluster=Cluster_node(array(mergevec),left=clust[lowestpair[<span class="number">0</span>]],right=clust[lowestpair[<span class="number">1</span>]],distance=closest,id=currentclustid)</span><br><span class="line">        currentclustid-=<span class="number">1</span></span><br><span class="line">        <span class="keyword">del</span> clust[lowestpair[<span class="number">1</span>]]</span><br><span class="line">        <span class="keyword">del</span> clust[lowestpair[<span class="number">0</span>]]</span><br><span class="line">        clust.append(newcluster)</span><br><span class="line">    <span class="keyword">return</span> clust[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_clusters</span><span class="params">(clust,dist)</span>:</span></span><br><span class="line">    clusters=&#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> clust.distance&lt;dist:</span><br><span class="line">        <span class="keyword">return</span> [clust]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cl=[]</span><br><span class="line">        cr=[]</span><br><span class="line">        <span class="keyword">if</span> clust.left!=<span class="keyword">None</span>:</span><br><span class="line">            c1=extract_clusters(clust.left,dist=dist)</span><br><span class="line">        <span class="keyword">if</span> clust.right!=<span class="keyword">None</span>:</span><br><span class="line">            cr=extract_clusters(clust.right,dist=dist)</span><br><span class="line">        <span class="keyword">return</span> cl+cr</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cluster_elements</span><span class="params">(clust)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> clust.id&gt;=<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> [clust.id]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cl=[]</span><br><span class="line">        cr=[]</span><br><span class="line">        <span class="keyword">if</span> clust.left!=<span class="keyword">None</span>:</span><br><span class="line">            c1=get_cluster_elements(clust.left)</span><br><span class="line">        <span class="keyword">if</span> clust.right!=<span class="keyword">None</span>:</span><br><span class="line">            cr=get_cluster_elements(clust.right)</span><br><span class="line">        <span class="keyword">return</span> cl+cr</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printclust</span><span class="params">(clust,labels=None,n=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        print(<span class="string">' '</span>,end=<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">if</span> clust.id&lt;<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'-'</span>,end=<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> labels==<span class="keyword">None</span>:</span><br><span class="line">            print(clust.id,end=<span class="string">''</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(labels[clust.id],end=<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">if</span> clust.left!=<span class="keyword">None</span>:</span><br><span class="line">        printclust(clust.left,labels=labels,n=n+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> clust.right!=<span class="keyword">None</span>:</span><br><span class="line">        printclust(clust.right,labels=labels,n=n+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getheight</span><span class="params">(clust)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> clust.left==<span class="keyword">None</span> <span class="keyword">and</span> clust.right==<span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> getheight(clust.left)+getheight(clust.right)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getdepth</span><span class="params">(clust)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> clust.left==<span class="keyword">None</span> <span class="keyword">and</span> clust.right==<span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> max(getheight(clust.left),getheight(clust.right))+clust.distance</span><br></pre></td></tr></table></figure></p>
<p>下面是几个城市的GDP等信息，根据这些信息，写一个SOM网络，使之对下面城市进行聚类。并且，将结果画在一个二维平面上。</p>
<p>//表1中，X。为人均GDP(元)；X2为工业总产值(亿元)；X。为社会消费品零售总额(亿元)；x。为批发零售贸易总额(亿元)；x。为地区货运总量(万吨)，表1中数据来自2002年城市统计年鉴。</p>
<p>//城市 X1 X2 X3 Xa X5<br>北京 27527 2738.30 1494.83 3055.63 30500<br>青岛 29682 1212.02 182.80 598.06 29068<br>天津 22073 2663.56 782.33 1465.65 28151<br>烟台 21017 298.73 92.71 227.39 8178<br>石家庄 25584 467.42 156.02 763.46 12415<br>郑州 17330 261.80 215.63 402.98 7373<br>唐山 19387 338.67 95.73 199.69 14522<br>武汉 17882 1020.84 685.82 1452 16244<br>太原 13919 304.13 141.94 155.22 15170<br>长沙 26327 241.76 269.93 369.83 7550<br>呼和浩特 13738 82.23 69.27 108.12 2415<br>衡阳 12386 61.53 63.95 72.65 3004<br>沈阳 21736 729.04 590.26 1752.4 15156<br>广州 42828 2446.97 1166.10 3214.19 24500<br>大连 34659 1003.56 431.83 728.08 19736<br>深圳 152099 3079.63 609.26 801.06 5167<br>长春 24799 900.26 309.75 173.99 10346<br>油头 19414 192.93 112.96 280.84 1443<br>哈尔滨 20737 402.73 360.38 762.94 8814<br>湛江 15290 228.45 99.08 149.16 5524<br>上海 40788 6935.57 1531.89 3921.2 49499<br>南宁 17715 109.39 142.08 264.32 3371<br>南京 26697 1579.21 401.20 1253.73 14120<br>柳州 17598 256.76 68.93 159.44 3397<br>徐州 19727 295.73 108.17 187.39 7124<br>海口 24782 100.13 81.03 142.54 2018<br>连云港 17869 112.18 47.94 134.89 4096<br>成都 22956 412.23 400.56 754.07 23724<br>杭州 31784 1615.63 373.28 1788.29 15841<br>重庆 9778 870.82 389.60 823.72 29470<br>宁波 46471 751.58 167.70 529.68 11182<br>贵阳 13176 207.95 108.93 285.27 4885<br>温州 29781 381.93 233.44 272.84 6292<br>昆明 24554 303.78 227.44 428.64 12084<br>合肥 19770 330.14 140.14 328.98 2903<br>西安 16002 449.14 323.37 558.27 7728<br>福州 33570 379.51 209.72 613.24 7280<br>兰州 16629 354.30 163.97 374.9 5401<br>厦门 42039 803.29 186.55 620.47 2547<br>西宁 7261 38.00 48.95 91.14 1837<br>南昌 19923 238.82 14.09 348.21 3246<br>银川 12779 77.74 41.22 53.16 1573<br>济南 25642 616.97 323.08 462.39 13057<br>乌鲁木齐 19793 251.19 129.05 277.8 9283</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">result = pd.read_csv(<span class="string">'./data/diqu.csv'</span>,sep=<span class="string">'\s+'</span>,encoding=<span class="string">'gbk'</span>)</span><br><span class="line"><span class="comment"># 将result归一化</span></span><br><span class="line"><span class="comment"># 标准化操作：from sklearn.preprocessing import StanderdScaler</span></span><br><span class="line"><span class="comment"># result_std=StandardScaler().fit_transform(reslut)</span></span><br><span class="line">result_norm = (result.iloc[:,<span class="number">1</span>:] - result.iloc[:,<span class="number">1</span>:].min()) / (result.iloc[:,<span class="number">1</span>:].max() - result.iloc[:,<span class="number">1</span>:].min())</span><br><span class="line">result_norm.head()</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">kmeans_model=KMeans(n_clusters=<span class="number">4</span>,random_state=<span class="number">1</span>)</span><br><span class="line">senator_distances=kmeans_model.fit_transform(result_norm.iloc[:,<span class="number">1</span>:])</span><br><span class="line">labels=kmeans_model.labels_</span><br><span class="line">print(pd.crosstab(labels,result[<span class="string">'城市'</span>]))</span><br><span class="line"><span class="comment"># democratic_outliers=votes[(labels==1)&amp;(result['party']!='D')]</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.scatter(x=senator_distances[:,<span class="number">0</span>],y=senator_distances[:,<span class="number">1</span>],c=labels)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/pasted-78.png" alt="upload successful"></p>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">GETAGGT IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/机器学习/">机器学习</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2018/05/10/SVM/"
                    data-tooltip="SVM"
                    aria-label="FRÜHER: SVM"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">FRÜHER</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2018/04/19/KNN/"
                    data-tooltip="KNN"
                    aria-label="NÄCHSTER: KNN"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NÄCHSTER</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://guoming576.cn/2018/04/24/聚类算法/"
                    title="Teilen auf Facebook"
                    aria-label="Teilen auf Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=http://guoming576.cn/2018/04/24/聚类算法/"
                    title="Teilen auf Twitter"
                    aria-label="Teilen auf Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=http://guoming576.cn/2018/04/24/聚类算法/"
                    title="Teilen auf Google Plus"
                    aria-label="Teilen auf Google Plus"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Nach oben">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 hero576. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2018/05/10/SVM/"
                    data-tooltip="SVM"
                    aria-label="FRÜHER: SVM"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">FRÜHER</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2018/04/19/KNN/"
                    data-tooltip="KNN"
                    aria-label="NÄCHSTER: KNN"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NÄCHSTER</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://guoming576.cn/2018/04/24/聚类算法/"
                    title="Teilen auf Facebook"
                    aria-label="Teilen auf Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=http://guoming576.cn/2018/04/24/聚类算法/"
                    title="Teilen auf Twitter"
                    aria-label="Teilen auf Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=http://guoming576.cn/2018/04/24/聚类算法/"
                    title="Teilen auf Google Plus"
                    aria-label="Teilen auf Google Plus"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Nach oben">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=http://guoming576.cn/2018/04/24/聚类算法/"
                        aria-label="Teilen auf Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Teilen auf Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=http://guoming576.cn/2018/04/24/聚类算法/"
                        aria-label="Teilen auf Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Teilen auf Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://plus.google.com/share?url=http://guoming576.cn/2018/04/24/聚类算法/"
                        aria-label="Teilen auf Google Plus"
                    >
                        <i class="fab fa-google-plus" aria-hidden="true"></i><span>Teilen auf Google Plus</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <h4 id="about-card-name">hero576</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/jquery.js"></script>
<script src="/assets/js/jquery.fancybox.js"></script>
<script src="/assets/js/thumbs.js"></script>
<script src="/assets/js/tranquilpeak.js"></script>
<!--SCRIPTS END-->


    




    </body>
</html>
