
<!DOCTYPE html>
<html lang="zh-CN">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="hero576的博客">
    <title>神经网络 - hero576的博客</title>
    <meta name="author" content="hero576">
    
        <meta name="keywords" content="py通红,">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"hero576","sameAs":["https://github.com/","http://stackoverflow.com/users","https://twitter.com/","https://facebook.com/","https://plus.google.com/","https://www.linkedin.com/profile/","mailto"]},"articleBody":"神经元（neuron）模型 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。 神经网络中最基本的成分是神经元（neuron）模型，即“简单单元”，在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过一个“阈值（threshold）”，那么它就会被激活，即“兴奋” 起来，向其他神经元发送化学物质。\n\n激活函数理想激活函数是阶跃函数，0 表示抑制神经元而1表示激活神经元阶跃函数具有不连续、不光滑等不好的性质，常用的是Sigmoid函数\nSigmoid函数Sigmoid函数可能在较大范围内变化的输入值挤压到（0,1）输出值范围内，因此有时也称为”挤压函数” 把这样许多个神经元按一定的层次结构连接起来，就得到了神经网络。\nReLu函数tanhsoftmax$max(0,(y-\\widehat{y}))$\n损失函数\n回归问题：SSE（Sum of Squared Error）均方误差和\n分类问题：CE（Cross Entropy）交叉熵\n\n感知机（Perceptron）与多层网络感知机有两层神经元组成权重 及阈值θ通过学习获得，阈值θ可看做一个固定输入为-1的哑结点（dummy node）所对应的权重 。这样权重和阈值可以统一学习。对训练样例(x,y)，感知机输出 ，学习规则：$$w_i←w_i+\\nabla{w_i}$$$$\\nabla{w_i}=η(y-\\widehat{y})x_i$$η∈(0,1)称为学习率(learning rate)。感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元。与或非问题都是线性可分（linearly separable）。感知机对线性可分学习过程一定收敛，非线性可分问题w难以稳定下来，不能求合适的解，如下图D。要解决非线性可分问题，需要考虑使用多层功能神经元网络结构中，输入层与输出层之间的神经元层成为隐含层（hidden layer），每层神经元与下一层神经元完全互联，神经元之间不存在同层连接，也不存在跨层连接，称为多层前馈网络结构(multi-layer feedforward nerual networks)\n\n多层网络：包含隐层的网络\n前馈网络：神经元之间不存在同层连接也不存在跨层连接  \n\n隐层和输出层具有激活函数，所以这两层的神经元亦称“功能单元”。多层前馈网络有强大的表示能力。只需一个包含足够多神经元的隐层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数。设置隐层神经元数，通常用“试错法”。\n\n主要特点：信号是前向传播的，而误差是反向传播的。\n主要过程：信号的前向传播，从输入层经过隐含层，最后到达输出层\n误差的反向传播，从输出层到隐含层，最后到输入层，依次调节隐含层到输出层的权重和偏置，输入层到隐含层的权重和偏置\n\n误差逆传播算法——BP神经网络 误差逆传播（error BackPropagation，简称BP）它是迄今为止最成功的神经网络学习算法，现实任务中使用神经网络时，大多在使用BP算法进行训练多层前馈神经网络，还可用于训练例如递归神经网络。\n链式法则$y=g(x)$，$z=h(y)$，$$\\nabla{x}→\\nabla{y}→\\nabla{z} , \\frac{dz}{dx}=\\frac{dz}{dy}\\frac{dy}{dx}$$$x=g(s)$，$y=h(s)$，$z=k(x,y)$，$$\\nabla{s}→\\nabla{x},\\nabla{y}→\\nabla{z} , \\frac{dz}{ds}=\\frac{dz}{dx}\\frac{dx}{ds}+\\frac{dz}{dy}\\frac{dy}{ds}$$\nBP算法过程给定训练集：$D=((x_1,y_1),(x_2,y_2)….(x_m,y_m)),x∈\\Bbb{R}^d,y∈\\Bbb{R}^l,$输入：d维特征向量，（d个属性）；输出：L个输出值（l维实值向量）；隐层：假定使用q个隐层神经元；输出层权重：$w_{ij}$；隐层权重：$v_{ij}$；输出层阈值：$θ_i$；隐层阈值：$γ_i$隐层输入；输出层输入；隐层第h个神经元输出：bh；假定功能单元均使用Sigmoid函数 。对训练，假定输出为 ，即，则网络在的均方误差为，未知的参数包括隐层及输出层权值、阈值。BP通过迭代学习，在每一轮采用广义的感知机学习规划对参数进行更新估计：。BP算法基于梯度下降策略（gradient descent），以目标负梯度方向对参数进行调整。对于误差Ek，给定学习率：η：\n由于，可得到 。Sigmoid函数有以下性质： ，所以：最终推得：其他参数的推导式同样的方法： 。其中：学习率，控制迭代中的更新步长，太大容易震荡，太小则收敛过慢。其中wθ与vγ的学习率不一定相等。\nBP算法流程算法的工作流程：\n标准BP算法与累计BP算法主要目标：最小化训练集D上的累计误差 。前面算法更新规则是基于单个Ek推导的，也称作“标准BP算法”。若使用基于累计误差最小化的更新规则，成为累计误差逆传播算法（accumulated errror backpropagation）。两者都很常用：\n| ————- |—–:||标准BP算法|    1、每次针对单个训练样例更新权值与阈值；2、参数更新频繁，不同样例可以抵消，需要多次迭代|\n|累计BP算法|    1、其优化目标是最小化整个训练集上的累计误差；2、读取整个训练集一遍才对参数进行更新，参数更新频率较低|\n累计BP算法更新频率低，防止不同样例导致训练出现抵消的现象。在很多任务中，累计误差下降到一定程度后，进一步下降会非常缓慢，这是标准BP算法往往会获得较好的解，尤其当训练集非常大时效果更明显。\n缓解过拟合主要策略\n\n早停early stopping将训练数据分为训练集和验证集。训练集计算梯度和更新，验证估计误差。1、若训练误差连续a轮的变化小于b,则停止训练2、使用验证集：若训练误差降低，验证误差升高，则停止训练。返回具有最小验证误差的链接权重和阈值。\n正则化regularization    在误差目标函数中，增加一项描述网络复杂度：例如连接权和阈值的平方和误差目标函数改为： ， 用于对经验误差和网络复杂度进行折中。偏好比较小的连接权和阈值，使网络输出更“光滑”\n\n全局最小与局部极小神经网络的训练过程可看作一个参数寻优过程：在参数空间中，寻找一组最优参数使得误差最小特点：存在多个“局部极小”；只有一个“全局最小”常用策略跳出局部极小\n\n不同参数进行初始化    \n模拟退火（simulated annealing）    以一定概率接收比当前解更差的结果，每部迭代中，接受次优解的概率随时间推移而降低。\n随机梯度下降    计算梯度时增加随机因素，即使陷入局部极小也有机会跳出继续搜索。\n遗传算法（genetic algorithms）    \n\n其他常见神经网络模型RBF网络RBF（Radial Basis Function，径向基函数）网络在分类任务中除BP之外最常用的一种•    单隐层前馈神经网络•    使用径向基函数作为隐层神经元激活函数ρ： ，定义为样本x到数据中心ci之间欧式距离的单调函数，常用高斯径向基函数。 。ci表示隐层神经元对应的中心、wi表示权重。•    输出层是隐层神经元输出的线性组合训练RBF网络：•    确定神经元中心ci，常用的方式包括随机采样、聚类等•    利用BP算法等确定参数wi和βi。\nART网络ART（Adaptive Resonance Theory，自适应谐振理论）竞争学习的代表，是一种常用的无监督学习策略。该策略网络输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活。其他神经元被抑制。包含比较层、识别层、识别阈值和重置模块。\nSOM网络SOM（Self-Organizing Map，自组织映射）网络是最常用的聚类方法之一：•    竞争型的无监督神经网络•    将高维数据映射到低维空间，并保持输入数据在高维空间的拓扑结构。即将高维空间中相似的样本点映射到网络输出层中邻近神经元•    每个神经元拥有一个权向量•    目标：为每个输出层神经元找到合适的权向量以保持拓扑结构训练•    网络接收输入样本后，将会确定输出层的“获胜”神经元（“胜者通吃”）•    获胜神经元的权向量将向当前输入样本移动\n级联相关网络：“构造性”神经网络的代表构造性神经网络：将网络结构也当做学习的目标，并在训练过程中找到最符合的网络结构。是结构自适应网络的重要代表。训练•    开始时只有输入层和输出层•    级联（Cascade）：新的隐层节点逐渐加入，从而创建起层级结构•    相关（Correlation）：最大化新节点的输出与网络误差之间的相关性\nElman网络：递归神经网络的代表•    网络可以有环形结构，可让使一些神经元的输出反馈回来最为输入•    t 时刻网络的输出状态： 由 t 时刻的输入状态和 t-1时刻的网络状态共同决定Elman网络是最常用的递归神经网络之一•    结构与前馈神经网络很相似，但隐层神经元的输出被反馈回来•    使用推广的BP算法训练\nBolyzmann机：”基于能量的模型”的代表深度学习•    卷积神经网络CNN\n•    每个卷积层包含多个特征映射，每个特征映射是一个由多个神经元构成的“平面”，通过一种卷积滤波器提取输入的一种特征•    采样层亦称“汇合层”，其作用是基于局部相关性原理进行亚采样，从而在减少数据量的同事保留有用信息•    连接层就是传统神经网络对隐层与输出层的全连接典型的深度学习模型就是很深层的神经网络\n","dateCreated":"2018-05-23T10:41:00+08:00","dateModified":"2018-06-08T15:24:15+08:00","datePublished":"2018-05-23T10:41:00+08:00","description":"","headline":"神经网络","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"http://guoming576.cn/2018/05/23/神经网络/"},"publisher":{"@type":"Organization","name":"hero576","sameAs":["https://github.com/","http://stackoverflow.com/users","https://twitter.com/","https://facebook.com/","https://plus.google.com/","https://www.linkedin.com/profile/","mailto"]},"url":"http://guoming576.cn/2018/05/23/神经网络/","keywords":"机器学习"}</script>
    <meta name="description" content="神经元（neuron）模型 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。 神经网络中最基本的成分是神经元（neuron）模型，即“简单单元”，在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过一个“阈值（threshold）”，那么">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="blog">
<meta property="og:title" content="神经网络">
<meta property="og:url" content="http://guoming576.cn/2018/05/23/神经网络/index.html">
<meta property="og:site_name" content="hero576的博客">
<meta property="og:description" content="神经元（neuron）模型 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。 神经网络中最基本的成分是神经元（neuron）模型，即“简单单元”，在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过一个“阈值（threshold）”，那么">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://guoming576.cn/images/pasted-36.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-37.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-38.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-41.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-42.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-43.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-45.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-46.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-47.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-48.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-49.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-50.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-51.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-52.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-53.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-54.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-55.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-56.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-57.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-58.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-59.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-60.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-61.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-62.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-63.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-64.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-65.png">
<meta property="og:image" content="http://guoming576.cn/images/pasted-66.png">
<meta property="og:updated_time" content="2018-06-08T07:24:15.874Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="神经网络">
<meta name="twitter:description" content="神经元（neuron）模型 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。 神经网络中最基本的成分是神经元（neuron）模型，即“简单单元”，在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过一个“阈值（threshold）”，那么">
<meta name="twitter:image" content="http://guoming576.cn/images/pasted-36.png">
    
    
        
    
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/all.css">
    <link rel="stylesheet" href="/assets/css/jquery.fancybox.css">
    <link rel="stylesheet" href="/assets/css/thumbs.css">
    <link rel="stylesheet" href="/assets/css/tranquilpeak.css">
    <!--STYLES END-->
    

    

    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/ "
            aria-label=""
        >
            hero576的博客
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Öffne den Link: /#about"
            >
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Kategorien"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Kategorien</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archiv"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archiv</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="Suche"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Suche</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="Über"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Über</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="http://stackoverflow.com/users"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Stack Overflow"
                        >
                        <i class="sidebar-button-icon fab fa-stack-overflow" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Stack Overflow</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://facebook.com/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Facebook"
                        >
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://plus.google.com/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Google Plus"
                        >
                        <i class="sidebar-button-icon fab fa-google-plus" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Google Plus</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.linkedin.com/profile/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="LinkedIn"
                        >
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/mailto"
                            
                            rel="noopener"
                            title="E-Mail"
                        >
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">E-Mail</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            神经网络
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2018-05-23T10:41:00+08:00">
	
		    23 5月 2018
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/机器学习/">机器学习</a>


    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <h2 id="神经元（neuron）模型"><a href="#神经元（neuron）模型" class="headerlink" title="神经元（neuron）模型"></a>神经元（neuron）模型</h2><p> 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。<br> 神经网络中最基本的成分是神经元（neuron）模型，即“简单单元”，在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过一个“阈值（threshold）”，那么它就会被激活，即“兴奋” 起来，向其他神经元发送化学物质。</p>
<p><img src="/images/pasted-36.png" alt="upload successful"></p>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>理想激活函数是阶跃函数，0 表示抑制神经元而1表示激活神经元<br>阶跃函数具有不连续、不光滑等不好的性质，常用的是Sigmoid函数</p>
<h4 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h4><p><img src="/images/pasted-37.png" alt="upload successful"><br>Sigmoid函数可能在较大范围内变化的输入值挤压到（0,1）输出值范围内，因此有时也称为”挤压函数”<br> 把这样许多个神经元按一定的层次结构连接起来，就得到了神经网络。</p>
<h4 id="ReLu函数"><a href="#ReLu函数" class="headerlink" title="ReLu函数"></a>ReLu函数</h4><h4 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h4><h4 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h4><p>$max(0,(y-\widehat{y}))$</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><ul>
<li>回归问题：SSE（Sum of Squared Error）均方误差和</li>
<li>分类问题：CE（Cross Entropy）交叉熵</li>
</ul>
<h2 id="感知机（Perceptron）与多层网络"><a href="#感知机（Perceptron）与多层网络" class="headerlink" title="感知机（Perceptron）与多层网络"></a>感知机（Perceptron）与多层网络</h2><p>感知机有两层神经元组成<br><img src="/images/pasted-38.png" alt="upload successful"><br>权重 及阈值θ通过学习获得，阈值θ可看做一个固定输入为-1的哑结点（dummy node）所对应的权重 。这样权重和阈值可以统一学习。对训练样例(x,y)，感知机输出 ，学习规则：<br>$$w_i←w_i+\nabla{w_i}$$<br>$$\nabla{w_i}=η(y-\widehat{y})x_i$$<br>η∈(0,1)称为学习率(learning rate)。<br>感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元。与或非问题都是线性可分（linearly separable）。感知机对线性可分学习过程一定收敛，非线性可分问题w难以稳定下来，不能求合适的解，如下图D。<br><img src="/images/pasted-41.png" alt="upload successful"><br>要解决非线性可分问题，需要考虑使用多层功能神经元<br><img src="/images/pasted-42.png" alt="upload successful"><br><img src="/images/pasted-43.png" alt="upload successful"><br>网络结构中，输入层与输出层之间的神经元层成为隐含层（hidden layer），每层神经元与下一层神经元完全互联，神经元之间不存在同层连接，也不存在跨层连接，称为多层前馈网络结构(multi-layer feedforward nerual networks)</p>
<ul>
<li>多层网络：包含隐层的网络</li>
<li>前馈网络：神经元之间不存在同层连接也不存在跨层连接  </li>
</ul>
<p>隐层和输出层具有激活函数，所以这两层的神经元亦称“功能单元”。多层前馈网络有强大的表示能力。只需一个包含足够多神经元的隐层，多层前馈神经网络就能以任意精度逼近任意复杂度的连续函数。设置隐层神经元数，通常用“试错法”。</p>
<ul>
<li>主要特点：信号是前向传播的，而误差是反向传播的。</li>
<li>主要过程：信号的前向传播，从输入层经过隐含层，最后到达输出层</li>
<li>误差的反向传播，从输出层到隐含层，最后到输入层，依次调节隐含层到输出层的权重和偏置，输入层到隐含层的权重和偏置</li>
</ul>
<h2 id="误差逆传播算法——BP神经网络"><a href="#误差逆传播算法——BP神经网络" class="headerlink" title="误差逆传播算法——BP神经网络"></a>误差逆传播算法——BP神经网络</h2><p> 误差逆传播（error BackPropagation，简称BP）它是迄今为止最成功的神经网络学习算法，现实任务中使用神经网络时，大多在使用BP算法进行训练多层前馈神经网络，还可用于训练例如递归神经网络。</p>
<h3 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h3><p>$y=g(x)$，$z=h(y)$，$$\nabla{x}→\nabla{y}→\nabla{z} , \frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx}$$<br>$x=g(s)$，$y=h(s)$，$z=k(x,y)$，$$\nabla{s}→\nabla{x},\nabla{y}→\nabla{z} , \frac{dz}{ds}=\frac{dz}{dx}\frac{dx}{ds}+\frac{dz}{dy}\frac{dy}{ds}$$</p>
<h3 id="BP算法过程"><a href="#BP算法过程" class="headerlink" title="BP算法过程"></a>BP算法过程</h3><p>给定训练集：$D=((x_1,y_1),(x_2,y_2)….(x_m,y_m)),x∈\Bbb{R}^d,y∈\Bbb{R}^l,$<br>输入：d维特征向量，（d个属性）；<br>输出：L个输出值（l维实值向量）；<br>隐层：假定使用q个隐层神经元；<br>输出层权重：$w_{ij}$；隐层权重：$v_{ij}$；输出层阈值：$θ_i$；隐层阈值：$γ_i$<br>隐层输入<br><img src="/images/pasted-45.png" alt="upload successful">；<br>输出层输入<br><img src="/images/pasted-46.png" alt="upload successful">；<br>隐层第h个神经元输出：bh；<br>假定功能单元均使用Sigmoid函数 。<br><img src="/images/pasted-47.png" alt="upload successful"><br>对训练<br><img src="/images/pasted-48.png" alt="upload successful">，假定输出为<br><img src="/images/pasted-49.png" alt="upload successful"> ，即<br><img src="/images/pasted-50.png" alt="upload successful">，则网络在<br><img src="/images/pasted-51.png" alt="upload successful">的均方误差为<br><img src="/images/pasted-52.png" alt="upload successful">，未知的参数包括隐层及输出层权值、阈值。<br>BP通过迭代学习，在每一轮采用广义的感知机学习规划对参数进行更新估计：<br><img src="/images/pasted-53.png" alt="upload successful">。BP算法基于梯度下降策略（gradient descent），以目标负梯度方向对参数进行调整。对于误差Ek，给定学习率：η：</p>
<p><img src="/images/pasted-54.png" alt="upload successful"><br>由于<br><img src="/images/pasted-55.png" alt="upload successful">，可得到<br><img src="/images/pasted-56.png" alt="upload successful"> 。<br>Sigmoid函数有以下性质：<br><img src="/images/pasted-57.png" alt="upload successful"> ，所以<br><img src="/images/pasted-58.png" alt="upload successful">：<br><img src="/images/pasted-59.png" alt="upload successful"><br>最终推得：<br><img src="/images/pasted-60.png" alt="upload successful"><br>其他参数的推导式同样的方法：<br><img src="/images/pasted-61.png" alt="upload successful"> 。<br>其中：<br><img src="/images/pasted-62.png" alt="upload successful"><br>学习率<br><img src="/images/pasted-63.png" alt="upload successful">，控制迭代中的更新步长，太大容易震荡，太小则收敛过慢。其中wθ与vγ的学习率不一定相等。</p>
<h3 id="BP算法流程"><a href="#BP算法流程" class="headerlink" title="BP算法流程"></a>BP算法流程</h3><p>算法的工作流程：<br><img src="/images/pasted-64.png" alt="upload successful"></p>
<h3 id="标准BP算法与累计BP算法"><a href="#标准BP算法与累计BP算法" class="headerlink" title="标准BP算法与累计BP算法"></a>标准BP算法与累计BP算法</h3><p>主要目标：最小化训练集D上的累计误差 。前面算法更新规则是基于单个Ek推导的，也称作“标准BP算法”。若使用基于累计误差最小化的更新规则，成为累计误差逆传播算法（accumulated errror backpropagation）。两者都很常用：</p>
<p>| ————- |—–:|<br>|标准BP算法|    1、每次针对单个训练样例更新权值与阈值；2、参数更新频繁，不同样例可以抵消，需要多次迭代|</p>
<p>|累计BP算法|    1、其优化目标是最小化整个训练集上的累计误差；<br>2、读取整个训练集一遍才对参数进行更新，参数更新频率较低|</p>
<p>累计BP算法更新频率低，防止不同样例导致训练出现抵消的现象。在很多任务中，累计误差下降到一定程度后，进一步下降会非常缓慢，这是标准BP算法往往会获得较好的解，尤其当训练集非常大时效果更明显。</p>
<h3 id="缓解过拟合"><a href="#缓解过拟合" class="headerlink" title="缓解过拟合"></a>缓解过拟合</h3><p>主要策略</p>
<ul>
<li>早停early stopping<br>将训练数据分为训练集和验证集。训练集计算梯度和更新，验证估计误差。<br>1、若训练误差连续a轮的变化小于b,则停止训练<br>2、使用验证集：若训练误差降低，验证误差升高，则停止训练。<br>返回具有最小验证误差的链接权重和阈值。</li>
<li>正则化<br>regularization    在误差目标函数中，增加一项描述网络复杂度：例如连接权和阈值的平方和<br>误差目标函数改为： ， 用于对经验误差和网络复杂度进行折中。偏好比较小的连接权和阈值，使网络输出更“光滑”</li>
</ul>
<h2 id="全局最小与局部极小"><a href="#全局最小与局部极小" class="headerlink" title="全局最小与局部极小"></a>全局最小与局部极小</h2><p><img src="/images/pasted-65.png" alt="upload successful"><br>神经网络的训练过程可看作一个参数寻优过程：<br>在参数空间中，寻找一组最优参数使得误差最小<br>特点：存在多个“局部极小”；只有一个“全局最小”<br>常用策略跳出局部极小</p>
<ul>
<li>不同参数进行初始化    </li>
<li>模拟退火（simulated annealing）    以一定概率接收比当前解更差的结果，每部迭代中，接受次优解的概率随时间推移而降低。</li>
<li>随机梯度下降    计算梯度时增加随机因素，即使陷入局部极小也有机会跳出继续搜索。</li>
<li>遗传算法（genetic algorithms）    </li>
</ul>
<h2 id="其他常见神经网络模型"><a href="#其他常见神经网络模型" class="headerlink" title="其他常见神经网络模型"></a>其他常见神经网络模型</h2><h3 id="RBF网络"><a href="#RBF网络" class="headerlink" title="RBF网络"></a>RBF网络</h3><p>RBF（Radial Basis Function，径向基函数）网络在分类任务中除BP之外最常用的一种<br>•    单隐层前馈神经网络<br>•    使用径向基函数作为隐层神经元激活函数ρ： ，定义为样本x到数据中心ci之间欧式距离的单调函数，常用高斯径向基函数。 。ci表示隐层神经元对应的中心、wi表示权重。<br>•    输出层是隐层神经元输出的线性组合<br>训练RBF网络：<br>•    确定神经元中心ci，常用的方式包括随机采样、聚类等<br>•    利用BP算法等确定参数wi和βi。</p>
<h3 id="ART网络"><a href="#ART网络" class="headerlink" title="ART网络"></a>ART网络</h3><p>ART（Adaptive Resonance Theory，自适应谐振理论）竞争学习的代表，是一种常用的无监督学习策略。该策略网络输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活。其他神经元被抑制。包含比较层、识别层、识别阈值和重置模块。</p>
<h3 id="SOM网络"><a href="#SOM网络" class="headerlink" title="SOM网络"></a>SOM网络</h3><p>SOM（Self-Organizing Map，自组织映射）网络是最常用的聚类方法之一：<br>•    竞争型的无监督神经网络<br>•    将高维数据映射到低维空间，并保持输入数据在高维空间的拓扑结构。即将高维空间中相似的样本点映射到网络输出层中邻近神经元<br>•    每个神经元拥有一个权向量<br>•    目标：为每个输出层神经元找到合适的权向量以保持拓扑结构<br>训练<br>•    网络接收输入样本后，将会确定输出层的“获胜”神经元（“胜者通吃”）<br>•    获胜神经元的权向量将向当前输入样本移动</p>
<h3 id="级联相关网络：“构造性”神经网络的代表"><a href="#级联相关网络：“构造性”神经网络的代表" class="headerlink" title="级联相关网络：“构造性”神经网络的代表"></a>级联相关网络：“构造性”神经网络的代表</h3><p>构造性神经网络：将网络结构也当做学习的目标，并在训练过程中找到最符合的网络结构。是结构自适应网络的重要代表。<br>训练<br>•    开始时只有输入层和输出层<br>•    级联（Cascade）：新的隐层节点逐渐加入，从而创建起层级结构<br>•    相关（Correlation）：最大化新节点的输出与网络误差之间的相关性</p>
<h3 id="Elman网络：递归神经网络的代表"><a href="#Elman网络：递归神经网络的代表" class="headerlink" title="Elman网络：递归神经网络的代表"></a>Elman网络：递归神经网络的代表</h3><p>•    网络可以有环形结构，可让使一些神经元的输出反馈回来最为输入<br>•    t 时刻网络的输出状态： 由 t 时刻的输入状态和 t-1时刻的网络状态共同决定<br>Elman网络是最常用的递归神经网络之一<br>•    结构与前馈神经网络很相似，但隐层神经元的输出被反馈回来<br>•    使用推广的BP算法训练</p>
<h3 id="Bolyzmann机：”基于能量的模型”的代表"><a href="#Bolyzmann机：”基于能量的模型”的代表" class="headerlink" title="Bolyzmann机：”基于能量的模型”的代表"></a>Bolyzmann机：”基于能量的模型”的代表</h3><h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p>•    卷积神经网络CNN</p>
<p><img src="/images/pasted-66.png" alt="upload successful"><br>•    每个卷积层包含多个特征映射，每个特征映射是一个由多个神经元构成的“平面”，通过一种卷积滤波器提取输入的一种特征<br>•    采样层亦称“汇合层”，其作用是基于局部相关性原理进行亚采样，从而在减少数据量的同事保留有用信息<br>•    连接层就是传统神经网络对隐层与输出层的全连接<br>典型的深度学习模型就是很深层的神经网络</p>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">GETAGGT IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/机器学习/">机器学习</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2018/06/06/降维与度量学习/"
                    data-tooltip="降维与度量学习"
                    aria-label="FRÜHER: 降维与度量学习"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">FRÜHER</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2018/05/16/贝叶斯/"
                    data-tooltip="贝叶斯分类器"
                    aria-label="NÄCHSTER: 贝叶斯分类器"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NÄCHSTER</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://guoming576.cn/2018/05/23/神经网络/"
                    title="Teilen auf Facebook"
                    aria-label="Teilen auf Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=http://guoming576.cn/2018/05/23/神经网络/"
                    title="Teilen auf Twitter"
                    aria-label="Teilen auf Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=http://guoming576.cn/2018/05/23/神经网络/"
                    title="Teilen auf Google Plus"
                    aria-label="Teilen auf Google Plus"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Nach oben">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 hero576. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2018/06/06/降维与度量学习/"
                    data-tooltip="降维与度量学习"
                    aria-label="FRÜHER: 降维与度量学习"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">FRÜHER</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2018/05/16/贝叶斯/"
                    data-tooltip="贝叶斯分类器"
                    aria-label="NÄCHSTER: 贝叶斯分类器"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NÄCHSTER</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Diesen Beitrag teilen"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://guoming576.cn/2018/05/23/神经网络/"
                    title="Teilen auf Facebook"
                    aria-label="Teilen auf Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=http://guoming576.cn/2018/05/23/神经网络/"
                    title="Teilen auf Twitter"
                    aria-label="Teilen auf Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=http://guoming576.cn/2018/05/23/神经网络/"
                    title="Teilen auf Google Plus"
                    aria-label="Teilen auf Google Plus"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Nach oben">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=http://guoming576.cn/2018/05/23/神经网络/"
                        aria-label="Teilen auf Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Teilen auf Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=http://guoming576.cn/2018/05/23/神经网络/"
                        aria-label="Teilen auf Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Teilen auf Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://plus.google.com/share?url=http://guoming576.cn/2018/05/23/神经网络/"
                        aria-label="Teilen auf Google Plus"
                    >
                        <i class="fab fa-google-plus" aria-hidden="true"></i><span>Teilen auf Google Plus</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <h4 id="about-card-name">hero576</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/jquery.js"></script>
<script src="/assets/js/jquery.fancybox.js"></script>
<script src="/assets/js/thumbs.js"></script>
<script src="/assets/js/tranquilpeak.js"></script>
<!--SCRIPTS END-->


    




    </body>
</html>
